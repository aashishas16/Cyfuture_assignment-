{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio to Text Converter using Whisper\n",
    "\n",
    "This notebook demonstrates how to convert audio files (MP3 format) to text using the Whisper model from Hugging Face."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Required Libraries\n",
    "\n",
    "First, let's install the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (4.50.0)\n",
      "Requirement already satisfied: datasets in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (3.4.1)\n",
      "Requirement already satisfied: soundfile in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (0.13.1)\n",
      "Requirement already satisfied: librosa in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (0.11.0)\n",
      "Requirement already satisfied: torch in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (2.6.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: filelock in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: requests in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from transformers) (0.29.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: pandas in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: fsspec[http]<=2024.12.0,>=2023.1.0 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from datasets) (2024.12.0)\n",
      "Requirement already satisfied: xxhash in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: aiohttp in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from datasets) (3.11.14)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: cffi>=1.0 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from librosa) (1.6.1)\n",
      "Requirement already satisfied: msgpack>=1.0 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from librosa) (4.12.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from librosa) (5.2.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from librosa) (1.13.1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: numba>=0.51.0 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: networkx in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (6.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (0.3.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from pooch>=1.1->librosa) (4.3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/tusharsingune/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers datasets soundfile librosa torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tusharsingune/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/tusharsingune/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "import os\n",
    "from IPython.display import Audio, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Whisper Model\n",
    "\n",
    "We'll use the Whisper model from Hugging Face. You can choose different model sizes based on your needs:\n",
    "- `openai/whisper-tiny`: Smallest model, fastest but less accurate\n",
    "- `openai/whisper-base`: Small model with decent accuracy\n",
    "- `openai/whisper-small`: Medium-sized model with good accuracy\n",
    "- `openai/whisper-medium`: Larger model with better accuracy\n",
    "- `openai/whisper-large-v2`: Largest model, most accurate but requires more resources\n",
    "\n",
    "For this example, we'll use the base model, but you can change it based on your requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on cpu\n"
     ]
    }
   ],
   "source": [
    "# Load model and processor\n",
    "model_name = \"openai/whisper-small\"\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(model_name)\n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Check if GPU is available and move model to GPU if possible\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Functions to Transcribe Audio Files\n",
    "\n",
    "We'll create three separate functions for different use cases:\n",
    "1. `transcribe_audio`: For transcribing a single audio file\n",
    "2. `transcribe_long_audio`: For transcribing longer audio files by processing them in chunks\n",
    "3. `batch_transcribe`: For transcribing multiple audio files in a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(audio_path, language=\"english\"):\n",
    "    \"\"\"\n",
    "    Transcribe an audio file using the Whisper model.\n",
    "    \n",
    "    Args:\n",
    "        audio_path (str): Path to the audio file (MP3 format)\n",
    "        language (str): Language of the audio (default: \"english\")\n",
    "        \n",
    "    Returns:\n",
    "        str: Transcribed text\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load and preprocess the audio file\n",
    "        print(f\"Loading audio file: {audio_path}\")\n",
    "        speech_array, sampling_rate = librosa.load(audio_path, sr=16000)\n",
    "        \n",
    "        # Display a sample of the audio\n",
    "        display(Audio(speech_array, rate=sampling_rate))\n",
    "        \n",
    "        # Process the audio with the Whisper processor (with attention mask to avoid warnings)\n",
    "        inputs = processor(\n",
    "            speech_array, \n",
    "            sampling_rate=sampling_rate, \n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        # Generate token ids\n",
    "        forced_decoder_ids = processor.get_decoder_prompt_ids(language=language, task=\"transcribe\")\n",
    "        \n",
    "        # Generate transcription with attention mask to avoid warnings\n",
    "        predicted_ids = model.generate(\n",
    "            inputs.input_features,\n",
    "            attention_mask=inputs.attention_mask,\n",
    "            forced_decoder_ids=forced_decoder_ids\n",
    "        )\n",
    "        \n",
    "        # Decode the predicted ids to text\n",
    "        transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
    "        \n",
    "        return transcription\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error transcribing audio: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_long_audio(audio_path, chunk_length_sec=30, language=\"english\"):\n",
    "    \"\"\"\n",
    "    Transcribe a long audio file by processing it in chunks.\n",
    "    \n",
    "    Args:\n",
    "        audio_path (str): Path to the audio file\n",
    "        chunk_length_sec (int): Length of each chunk in seconds\n",
    "        language (str): Language of the audio\n",
    "        \n",
    "    Returns:\n",
    "        str: Transcribed text\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load audio file\n",
    "        print(f\"Loading audio file: {audio_path}\")\n",
    "        speech_array, sampling_rate = librosa.load(audio_path, sr=16000)\n",
    "        \n",
    "        # Calculate chunk size in samples\n",
    "        chunk_length_samples = chunk_length_sec * sampling_rate\n",
    "        \n",
    "        # Calculate number of chunks\n",
    "        num_chunks = int(np.ceil(len(speech_array) / chunk_length_samples))\n",
    "        \n",
    "        print(f\"Processing audio in {num_chunks} chunks...\")\n",
    "        \n",
    "        # Process each chunk\n",
    "        transcription_parts = []\n",
    "        for i in range(num_chunks):\n",
    "            print(f\"Processing chunk {i+1}/{num_chunks}\")\n",
    "            \n",
    "            # Extract chunk\n",
    "            start = int(i * chunk_length_samples)\n",
    "            end = int(min(len(speech_array), (i + 1) * chunk_length_samples))\n",
    "            chunk = speech_array[start:end]\n",
    "            \n",
    "            # Process the chunk with attention mask to avoid warnings\n",
    "            inputs = processor(\n",
    "                chunk, \n",
    "                sampling_rate=sampling_rate, \n",
    "                return_tensors=\"pt\",\n",
    "                padding=\"max_length\",\n",
    "                return_attention_mask=True\n",
    "            )\n",
    "            inputs = inputs.to(device)\n",
    "            \n",
    "            # Generate token ids\n",
    "            forced_decoder_ids = processor.get_decoder_prompt_ids(language=language, task=\"transcribe\")\n",
    "            \n",
    "            # Generate transcription with attention mask\n",
    "            predicted_ids = model.generate(\n",
    "                inputs.input_features,\n",
    "                attention_mask=inputs.attention_mask,\n",
    "                forced_decoder_ids=forced_decoder_ids\n",
    "            )\n",
    "            \n",
    "            # Decode the predicted ids to text\n",
    "            chunk_transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
    "            transcription_parts.append(chunk_transcription)\n",
    "        \n",
    "        # Combine all chunks\n",
    "        full_transcription = \" \".join(transcription_parts)\n",
    "        return full_transcription\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error transcribing audio: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_transcribe(directory_path, language=\"english\", use_chunking=False, chunk_length_sec=30):\n",
    "    \"\"\"\n",
    "    Transcribe all MP3 files in a directory.\n",
    "    \n",
    "    Args:\n",
    "        directory_path (str): Path to the directory containing MP3 files\n",
    "        language (str): Language of the audio files (default: \"english\")\n",
    "        use_chunking (bool): Whether to use chunking for long audio files (default: False)\n",
    "        chunk_length_sec (int): Length of each chunk in seconds if use_chunking is True (default: 30)\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory_path):\n",
    "        print(f\"Directory not found: {directory_path}\")\n",
    "        return\n",
    "    \n",
    "    # Get all MP3 files in the directory\n",
    "    mp3_files = [f for f in os.listdir(directory_path) if f.lower().endswith('.mp3')]\n",
    "    \n",
    "    if not mp3_files:\n",
    "        print(f\"No MP3 files found in {directory_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(mp3_files)} MP3 files. Starting transcription...\")\n",
    "    \n",
    "    for i, mp3_file in enumerate(mp3_files, 1):\n",
    "        file_path = os.path.join(directory_path, mp3_file)\n",
    "        print(f\"\\nProcessing file {i}/{len(mp3_files)}: {mp3_file}\")\n",
    "        \n",
    "        # Transcribe the audio using the appropriate function\n",
    "        if use_chunking:\n",
    "            transcription = transcribe_long_audio(file_path, chunk_length_sec=chunk_length_sec, language=language)\n",
    "        else:\n",
    "            transcription = transcribe_audio(file_path, language=language)\n",
    "        \n",
    "        # Save the transcription to a text file\n",
    "        output_file = os.path.join(directory_path, os.path.splitext(mp3_file)[0] + \"_transcription.txt\")\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(transcription)\n",
    "        \n",
    "        print(f\"Transcription saved to: {output_file}\")\n",
    "    \n",
    "    print(\"\\nBatch transcription completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Transcribe a Single Audio File\n",
    "\n",
    "Use this example to transcribe a single audio file using the standard method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your MP3 file\n",
    "audio_file_path = 'path_to_your_audio.mp3'  # Replace with your actual file path\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(audio_file_path):\n",
    "    # Transcribe the audio\n",
    "    transcription = transcribe_audio(audio_file_path, language=\"english\")\n",
    "    \n",
    "    # Print the transcription\n",
    "    print(\"\\nTranscription:\")\n",
    "    print(transcription)\n",
    "    \n",
    "    # Save the transcription to a text file\n",
    "    output_file = os.path.splitext(audio_file_path)[0] + \"_transcription.txt\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(transcription)\n",
    "    \n",
    "    print(f\"\\nTranscription saved to: {output_file}\")\n",
    "else:\n",
    "    print(f\"File not found: {audio_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Transcribe a Long Audio File\n",
    "\n",
    "Use this example to transcribe a longer audio file by processing it in chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading audio file: Shape-of-You.mp3\n",
      "Processing audio in 9 chunks...\n",
      "Processing chunk 1/9\n",
      "Processing chunk 2/9\n",
      "Processing chunk 3/9\n",
      "Processing chunk 4/9\n",
      "Processing chunk 5/9\n",
      "Processing chunk 6/9\n",
      "Processing chunk 7/9\n",
      "Processing chunk 8/9\n",
      "Processing chunk 9/9\n",
      "\n",
      "Transcription:\n",
      " The club isn't the best place to find the lovers of the bar is where I go Me and my friends at the table doing shots, drinking fast and then we talk slow Come over and start up a conversation with just me and trust me I'll give it a chance  Now take my hand, stop, prepare the man on the jukebox and then we start to dance and I'm singing like girl you know I want your love, your love was handmade for somebody like me. I'm coming now, follow my lead. I may be crazy, don't mind me. Say boy, let's not talk too much, grab all my waist and put that body on me. I'm coming now, follow my lead. I'm coming now, follow my lead. I'm in love with the shape of you, we push and pull.  I'm in love with your body  We're going out on our first day You and me you thrifty so all you can eat fill up your bag and I fill up the plate We took for hours and hours about the sweet and sour and how your family's doing okay And leaving getting a taxi and kissing the back seat till the driver make your radio play and I'm singing like girl you know I want your love your love was handmade for me  I'm in love with the shape of you Push and pull like a magnet  She smells like you everyday discovering something brand new I'm in love with your body I'm in love with your body I'm in love with your body I'm in love with your body Everyday discovering something brand new I'm in love with the shape of you  Come on, be my baby, come on Come on, be my baby, come on Come on, be my baby, come on Come on, be my baby, come on Come on, be my baby, come on Come on, be my baby, come on Come on, be my baby, come on Come on, be my baby, come on I'm in love with this shape of you You push and pull like a magnet But my heart is falling too I'm in love with your body Last night you were in my room  Know my bedsheets smell like you Everything discovered is something brand I'm in love with your body Come on be my baby Come on, come on, be my baby I'm in love with your body Come on be my baby Come on, come on, be my baby I'm in love with your body Come on be my baby Come on, come on, be my baby I'm in love with your body Everything discovered is something brand I'm in love with the shape of you  You\n",
      "\n",
      "Transcription saved to: Shape-of-You_transcription.txt\n"
     ]
    }
   ],
   "source": [
    "# Path to your long MP3 file\n",
    "long_audio_file_path = 'Shape-of-You.mp3'  # Replace with your actual file path\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(long_audio_file_path):\n",
    "    # Transcribe the long audio file in chunks\n",
    "    transcription = transcribe_long_audio(\n",
    "        long_audio_file_path, \n",
    "        chunk_length_sec=30,  # Adjust chunk length as needed\n",
    "        language=\"english\"    # Change language as needed\n",
    "    )\n",
    "    \n",
    "    # Print the transcription\n",
    "    print(\"\\nTranscription:\")\n",
    "    print(transcription)\n",
    "    \n",
    "    # Save the transcription to a text file\n",
    "    output_file = os.path.splitext(long_audio_file_path)[0] + \"_transcription.txt\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(transcription)\n",
    "    \n",
    "    print(f\"\\nTranscription saved to: {output_file}\")\n",
    "else:\n",
    "    print(f\"File not found: {long_audio_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Batch Process Multiple Audio Files\n",
    "\n",
    "Use this example to transcribe all MP3 files in a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to directory containing MP3 files\n",
    "directory_path = 'path_to_directory_with_mp3_files'  # Replace with your actual directory path\n",
    "\n",
    "# Batch transcribe all MP3 files in the directory\n",
    "batch_transcribe(\n",
    "    directory_path,\n",
    "    language=\"english\",     # Change language as needed\n",
    "    use_chunking=True,      # Set to True for longer audio files, False for shorter ones\n",
    "    chunk_length_sec=30     # Adjust chunk length as needed if use_chunking is True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Transcribe Audio in a Different Language\n",
    "\n",
    "Use this example to transcribe audio in a language other than English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your non-English audio file\n",
    "non_english_audio_path = 'path_to_your_non_english_audio.mp3'  # Replace with your actual file path\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(non_english_audio_path):\n",
    "    # Choose the appropriate function based on audio length\n",
    "    # For shorter audio files:\n",
    "    transcription = transcribe_audio(non_english_audio_path, language=\"spanish\")  # Change language as needed\n",
    "    \n",
    "    # For longer audio files:\n",
    "    # transcription = transcribe_long_audio(non_english_audio_path, chunk_length_sec=30, language=\"spanish\")\n",
    "    \n",
    "    # Print the transcription\n",
    "    print(\"\\nTranscription:\")\n",
    "    print(transcription)\n",
    "    \n",
    "    # Save the transcription to a text file\n",
    "    output_file = os.path.splitext(non_english_audio_path)[0] + \"_transcription.txt\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(transcription)\n",
    "    \n",
    "    print(f\"\\nTranscription saved to: {output_file}\")\n",
    "else:\n",
    "    print(f\"File not found: {non_english_audio_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates how to use the Whisper model from Hugging Face to transcribe audio files in MP3 format to text. You can use this as a starting point for your audio transcription projects.\n",
    "\n",
    "Key features implemented:\n",
    "1. Single file transcription\n",
    "2. Batch processing of multiple files\n",
    "3. Support for different languages\n",
    "4. Handling of longer audio files through chunking\n",
    "5. Proper attention mask handling to avoid warnings\n",
    "\n",
    "Additional improvements you could make:\n",
    "1. Add support for more audio formats (WAV, FLAC, etc.)\n",
    "2. Implement a progress bar for batch processing\n",
    "3. Add a simple UI using ipywidgets\n",
    "4. Implement post-processing to improve punctuation and formatting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
